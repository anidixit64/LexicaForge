[tool.poetry]
name = "lexicaforge"
version = "0.1.0"
description = "Etymology and Cognate Graph API with advanced linguistic analysis"
authors = ["Your Name <your.email@example.com>"]

[tool.poetry.dependencies]
python = "^3.9"
fastapi = "^0.104.0"
strawberry-graphql = "^0.211.1"
sqlalchemy = "^2.0.23"
alembic = "^1.12.1"
psycopg2-binary = "^2.9.9"
pyspark = "^3.5.0"
dagster = "^1.5.13"
pytest = "^7.4.3"
httpx = "^0.25.1"
python-dotenv = "^1.0.0"
uvicorn = "^0.24.0"
networkx = "^3.2.1"
spacy = "^3.7.2"
nltk = "^3.8.1"
structlog = "^23.2.0"

[tool.poetry.group.dev.dependencies]
black = "^23.10.1"
isort = "^5.12.0"
flake8 = "^6.1.0"
mypy = "^1.6.1"
pytest-cov = "^4.1.0"
pre-commit = "^3.5.0"
bandit = "^1.7.5"
flake8-docstrings = "^1.7.0"
pytest-asyncio = "^0.21.1"
pytest-mock = "^3.12.0"
pytest-xdist = "^3.3.1"
pytest-benchmark = "^4.0.0"
pytest-randomly = "^3.15.0"
pytest-env = "^1.1.1"
pytest-sugar = "^0.9.7"
pytest-timeout = "^2.2.0"
coverage = "^7.4.0"
hypothesis = "^6.87.1"

[build-system]
requires = ["poetry-core"]
build-backend = "poetry.core.masonry.api"

[tool.black]
line-length = 88
target-version = ['py39']
include = '\.pyi?$'

[tool.isort]
profile = "black"
multi_line_output = 3

[tool.mypy]
python_version = "3.9"
warn_return_any = true
warn_unused_configs = true
disallow_untyped_defs = true
disallow_incomplete_defs = true
check_untyped_defs = true
disallow_untyped_decorators = true
no_implicit_optional = true
warn_redundant_casts = true
warn_unused_ignores = true
warn_no_return = true
warn_unreachable = true

[tool.bandit]
exclude_dirs = ["tests"]
skips = ["B101"]

[tool.pytest.ini_options]
testpaths = ["tests"]
python_files = ["test_*.py"]
python_classes = ["Test*"]
python_functions = ["test_*"]
addopts = """
    --verbose
    --cov=lexicaforge
    --cov-report=term-missing
    --cov-report=html
    --cov-fail-under=80
    --no-cov-on-fail
    --asyncio-mode=auto
    --strict-markers
    --benchmark-only
    --benchmark-group-by=func
    --benchmark-warmup=on
    --benchmark-warmup-iterations=1000
    --benchmark-min-rounds=100
"""
markers = [
    "unit: Unit tests",
    "integration: Integration tests",
    "e2e: End-to-end tests",
    "slow: Tests that take longer to run",
    "api: API-specific tests",
    "db: Database-specific tests",
    "nlp: NLP-specific tests",
    "rust: Rust integration tests",
] 